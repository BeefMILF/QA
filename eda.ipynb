{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://boolq/train.jsonl...\r\n",
      "- [1 files][  6.2 MiB/  6.2 MiB]                                                - [0 files][  3.1 MiB/  6.2 MiB]                                                \r\n",
      "Operation completed over 1 objects/6.2 MiB.                                      \r\n",
      "Copying gs://boolq/dev.jsonl...\r\n",
      "-\r[0 files][    0.0 B/  2.1 MiB]                                                - [1 files][  2.1 MiB/  2.1 MiB]                                                \r\n",
      "Operation completed over 1 objects/2.1 MiB.                                      \r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x ./boolq.sh\n",
    "!./boolq.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.jsonl  train.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/beefmilf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/beefmilf/anaconda3/envs/QA/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df size: (9427, 4)\n",
      "Dev df size: (3270, 4)\n",
      "Train params size,  input ids: (9427, 512), attention masks: (9427, 512), token_type ids: (9427, 512), answers(targets): (9427,)\n",
      "Dev params size,  input ids: (3270, 512), attention masks: (3270, 512), token_type ids: (3270, 512), answers(targets): (3270,)\n",
      "Validation params size,  input ids: (2274, 512), attention masks: (2274, 512), token_type ids: (2274, 512), answers(targets): (2274,)\n",
      "Test params size,  input ids: (996, 512), attention masks: (996, 512), token_type ids: (996, 512), answers(targets): (996,)\n",
      "CPU times: user 5.06 s, sys: 174 ms, total: 5.24 s\n",
      "Wall time: 8.4 s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from runner import make_data\n",
    "\n",
    "%time _, _, _, _ = make_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df size: (9427, 4)\n",
      "Dev df size: (3270, 4)\n",
      "Train params size,  input ids: (9427, 512), attention masks: (9427, 512), token_type ids: (9427, 512), answers(targets): (9427,)\n",
      "Dev params size,  input ids: (3270, 512), attention masks: (3270, 512), token_type ids: (3270, 512), answers(targets): (3270,)\n",
      "Validation params size,  input ids: (2274, 512), attention masks: (2274, 512), token_type ids: (2274, 512), answers(targets): (2274,)\n",
      "Test params size,  input ids: (996, 512), attention masks: (996, 512), token_type ids: (996, 512), answers(targets): (996,)\n",
      "train loader size: 3916\n",
      "valid loader size: 758\n",
      "test loader size: 758\n",
      "CPU times: user 5.48 s, sys: 220 ms, total: 5.7 s\n",
      "Wall time: 8.56 s\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "from runner import make_loaders\n",
    "\n",
    "%time loaders = make_loaders()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/beefmilf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/beefmilf/anaconda3/envs/QA/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "/home/beefmilf/anaconda3/envs/QA/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:118: UserWarning:\n",
      "\n",
      "Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\n",
      "INFO:metrics_logger:\n",
      "1/15 * Epoch 1 (_base): lr=1.000e-05 | momentum=0.8500\n",
      "1/15 * Epoch 1 (train): accuracy01=0.5187 | f1_score=0.5005 | loss=0.7696 | lr=1.000e-05 | momentum=0.8625\n",
      "1/15 * Epoch 1 (valid): accuracy01=0.5585 | f1_score=0.5769 | loss=0.6851\n",
      "1/15 * Epoch 1 (test): accuracy01=0.5585 | f1_score=0.5769 | loss=0.6851\n",
      "INFO:metrics_logger:\n",
      "2/15 * Epoch 2 (_base): lr=9.385e-06 | momentum=0.8538\n",
      "2/15 * Epoch 2 (train): accuracy01=0.5555 | f1_score=0.5301 | loss=0.7120 | lr=9.692e-06 | momentum=0.8519\n",
      "2/15 * Epoch 2 (valid): accuracy01=0.5818 | f1_score=0.6040 | loss=0.6703\n",
      "2/15 * Epoch 2 (test): accuracy01=0.5818 | f1_score=0.6040 | loss=0.6703\n",
      "INFO:metrics_logger:\n",
      "3/15 * Epoch 3 (_base): lr=8.769e-06 | momentum=0.8577\n",
      "3/15 * Epoch 3 (train): accuracy01=0.5907 | f1_score=0.5681 | loss=0.6759 | lr=9.077e-06 | momentum=0.8558\n",
      "3/15 * Epoch 3 (valid): accuracy01=0.6416 | f1_score=0.7033 | loss=0.6406\n",
      "3/15 * Epoch 3 (test): accuracy01=0.6416 | f1_score=0.7033 | loss=0.6406\n",
      "INFO:metrics_logger:\n",
      "4/15 * Epoch 4 (_base): lr=8.154e-06 | momentum=0.8615\n",
      "4/15 * Epoch 4 (train): accuracy01=0.6311 | f1_score=0.6094 | loss=0.6454 | lr=8.461e-06 | momentum=0.8596\n",
      "4/15 * Epoch 4 (valid): accuracy01=0.6376 | f1_score=0.6906 | loss=0.6369\n",
      "4/15 * Epoch 4 (test): accuracy01=0.6376 | f1_score=0.6906 | loss=0.6369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df size: (9427, 4)\n",
      "Dev df size: (3270, 4)\n",
      "Train params size,  input ids: (9427, 512), attention masks: (9427, 512), token_type ids: (9427, 512), answers(targets): (9427,)\n",
      "Dev params size,  input ids: (3270, 512), attention masks: (3270, 512), token_type ids: (3270, 512), answers(targets): (3270,)\n",
      "Validation params size,  input ids: (2274, 512), attention masks: (2274, 512), token_type ids: (2274, 512), answers(targets): (2274,)\n",
      "Test params size,  input ids: (996, 512), attention masks: (996, 512), token_type ids: (996, 512), answers(targets): (996,)\n",
      "train loader size: 979\n",
      "valid loader size: 190\n",
      "test loader size: 190\n",
      "Loaded model: google/bert_uncased_L-4_H-256_A-4\n",
      "Trainable parameters: 11171074\n",
      "Device: cuda\n",
      "[2020-07-04 16:46:06,397] \n",
      "1/15 * Epoch 1 (_base): lr=1.000e-05 | momentum=0.8500\n",
      "1/15 * Epoch 1 (train): accuracy01=0.5187 | f1_score=0.5005 | loss=0.7696 | lr=1.000e-05 | momentum=0.8625\n",
      "1/15 * Epoch 1 (valid): accuracy01=0.5585 | f1_score=0.5769 | loss=0.6851\n",
      "1/15 * Epoch 1 (test): accuracy01=0.5585 | f1_score=0.5769 | loss=0.6851\n",
      "[2020-07-04 16:47:24,611] \n",
      "2/15 * Epoch 2 (_base): lr=9.385e-06 | momentum=0.8538\n",
      "2/15 * Epoch 2 (train): accuracy01=0.5555 | f1_score=0.5301 | loss=0.7120 | lr=9.692e-06 | momentum=0.8519\n",
      "2/15 * Epoch 2 (valid): accuracy01=0.5818 | f1_score=0.6040 | loss=0.6703\n",
      "2/15 * Epoch 2 (test): accuracy01=0.5818 | f1_score=0.6040 | loss=0.6703\n",
      "[2020-07-04 16:48:42,683] \n",
      "3/15 * Epoch 3 (_base): lr=8.769e-06 | momentum=0.8577\n",
      "3/15 * Epoch 3 (train): accuracy01=0.5907 | f1_score=0.5681 | loss=0.6759 | lr=9.077e-06 | momentum=0.8558\n",
      "3/15 * Epoch 3 (valid): accuracy01=0.6416 | f1_score=0.7033 | loss=0.6406\n",
      "3/15 * Epoch 3 (test): accuracy01=0.6416 | f1_score=0.7033 | loss=0.6406\n",
      "[2020-07-04 16:50:01,723] \n",
      "4/15 * Epoch 4 (_base): lr=8.154e-06 | momentum=0.8615\n",
      "4/15 * Epoch 4 (train): accuracy01=0.6311 | f1_score=0.6094 | loss=0.6454 | lr=8.461e-06 | momentum=0.8596\n",
      "4/15 * Epoch 4 (valid): accuracy01=0.6376 | f1_score=0.6906 | loss=0.6369\n",
      "4/15 * Epoch 4 (test): accuracy01=0.6376 | f1_score=0.6906 | loss=0.6369\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "from runner import run_model\n",
    "\n",
    "run_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from config import custom_change\n",
    "\n",
    "config = {\n",
    "    'data_clean_flag': True,\n",
    "    'seed': 3,\n",
    "    'max_seq_len': 512,\n",
    "    'pretrained_model_name': 'google/bert_uncased_L-4_H-256_A-4',\n",
    "    'batch_size': 12,\n",
    "    'train_sampler_mode': 'balanced',\n",
    "    'lr': 2e-5,\n",
    "    'lr_range': (2e-5, 2e-6),\n",
    "    'grad_accum_steps': 4,\n",
    "    'num_epochs': 15,\n",
    "    'logdir': f'logs/google/bert_uncased_L-4_H-256_A-4'\n",
    "}\n",
    "\n",
    "custom_change(config, 'config.json', 'config_tmp.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}