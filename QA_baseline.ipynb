{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKr+AALL64xS5K2Lrm7FEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73da8aac0a244960aa1ea306c446038f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8a4fd589d122400092cd8e0ac81703f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_345a75cfa92644a0b38a3627f5b42108",
              "IPY_MODEL_8c226e751efe488c8bf33fc2cadca310"
            ]
          }
        },
        "8a4fd589d122400092cd8e0ac81703f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "345a75cfa92644a0b38a3627f5b42108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0506668d7f5b462089a08b5dce34471b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04a28ee25a21440bb2b6cdca945cedd3"
          }
        },
        "8c226e751efe488c8bf33fc2cadca310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1fd2dd2e4de34033856e60b113a7fae7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 1.35kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_127d6fb07ed04c3fa56f86f067513cac"
          }
        },
        "0506668d7f5b462089a08b5dce34471b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04a28ee25a21440bb2b6cdca945cedd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fd2dd2e4de34033856e60b113a7fae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "127d6fb07ed04c3fa56f86f067513cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1108e5acfa04e54a2c3d52927ac76b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_82919e548ebf4b4da8d632fc01d3fbb9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d5a2c4f8a8944a00b644a7ca3a1e97c9",
              "IPY_MODEL_b07464f10afb49609010944787c8c62f"
            ]
          }
        },
        "82919e548ebf4b4da8d632fc01d3fbb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5a2c4f8a8944a00b644a7ca3a1e97c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b1ac659e8c541b7aac578c7ec52a38f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00c52848cdf047e3aaec5881ad60ff3b"
          }
        },
        "b07464f10afb49609010944787c8c62f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a1f304ce65a41ffaeda33448903ef5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 1.18MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_571f317bf4e24689806e55980323bdb5"
          }
        },
        "2b1ac659e8c541b7aac578c7ec52a38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00c52848cdf047e3aaec5881ad60ff3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a1f304ce65a41ffaeda33448903ef5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "571f317bf4e24689806e55980323bdb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b11756ce1d314566b01eb8084dc1094c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_82c8757c63c04ccea414fac6a554088c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_21843431c77c4a13ab7b000b1b42d7f1",
              "IPY_MODEL_ee97699962614b9f825392c6adb828bc"
            ]
          }
        },
        "82c8757c63c04ccea414fac6a554088c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21843431c77c4a13ab7b000b1b42d7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25ae1edde9e74903a5b23ad813455b7a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d94a1000e31c4ce089163ae3f216c15b"
          }
        },
        "ee97699962614b9f825392c6adb828bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_265b8d4ee5264195873d73d4b5f9df42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 2.29MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1944539aa0d14b3eb172d317e667725e"
          }
        },
        "25ae1edde9e74903a5b23ad813455b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d94a1000e31c4ce089163ae3f216c15b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "265b8d4ee5264195873d73d4b5f9df42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1944539aa0d14b3eb172d317e667725e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeefMILF/QA/blob/master/QA_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucKS0_dVSbZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd06vTCzqj3y",
        "colab_type": "text"
      },
      "source": [
        "# Проект QA\n",
        "\n",
        "## Yes/No Questions\n",
        "\n",
        "Вы будете работать с корпусом BoolQ. Корпус состоит из вопросов, предполагающих бинарный ответ (да / нет), абзацев из Википедии,  содержащих ответ на вопрос, заголовка статьи, из которой извлечен абзац и непосредственно ответа (true / false).\n",
        "\n",
        "Корпус описан в статье:\n",
        "\n",
        "Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, Kristina Toutanova\n",
        "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions\n",
        "\n",
        "https://arxiv.org/abs/1905.10044\n",
        "\n",
        "\n",
        "Корпус (train-dev split) доступен в репозитории проекта:  https://github.com/google-research-datasets/boolean-questions\n",
        "\n",
        "Используйте для обучения train часть корпуса, для валидации и тестирования – dev часть. \n",
        "\n",
        "Каждый бонус пункт оцениватся в 1 балл. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDEsCCkoqj34",
        "colab_type": "text"
      },
      "source": [
        "### Пример вопроса: \n",
        "question: is batman and robin a sequel to batman forever\n",
        "\n",
        "title: Batman & Robin (film)\n",
        "\n",
        "answer: true\n",
        "\n",
        "passage: With the box office success of Batman Forever in June 1995, Warner Bros. immediately commissioned a sequel. They hired director Joel Schumacher and writer Akiva Goldsman to reprise their duties the following August, and decided it was best to fast track production for a June 1997 target release date, which is a break from the usual 3-year gap between films. Schumacher wanted to homage both the broad camp style of the 1960s television series and the work of Dick Sprang. The storyline of Batman & Robin was conceived by Schumacher and Goldsman during pre-production on A Time to Kill. Portions of Mr. Freeze's back-story were based on the Batman: The Animated Series episode ''Heart of Ice'', written by Paul Dini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu5CnuYdqj3_",
        "colab_type": "text"
      },
      "source": [
        "## Часть 1. Эксплоративный анализ\n",
        "1. Посчитайте долю yes и no классов в корпусе\n",
        "2. Оцените среднюю длину вопроса\n",
        "3. Оцените среднюю длину параграфа\n",
        "4. Предположите, по каким эвристикам были собраны вопросы (или найдите ответ в статье). Продемонстриуйте, как эти эвристики повлияли на структуру корпуса. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRTuUReAqj4D",
        "colab_type": "text"
      },
      "source": [
        "## Часть 2. Baseline\n",
        "1. Оцените accuracy точность совсем простого базового решения: присвоить каждой паре вопрос-ответ в dev части самый частый класс из train части\n",
        "2. Оцените accuracy чуть более сложного базового решения: fasttext на текстах, состоящих из склееных вопросов и абзацев (' '.join([question, passage]))\n",
        "\n",
        "Почему fasttext плохо справляется с этой задачей?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg84O0bfqj4G",
        "colab_type": "text"
      },
      "source": [
        "## Часть 3. Используем эмбеддинги предложений\n",
        "1. Постройте BERT эмбеддинги вопроса и абзаца. Обучите логистическую регрессию на конкатенированных эмбеддингах вопроса и абзаца и оцените accuracy этого решения. \n",
        "\n",
        "[bonus] Используйте другие модели эмбеддингов, доступные, например, в библиотеке 🤗 Transformers. Какая модель эмбеддингов даст лучшие результаты?\n",
        "\n",
        "[bonus] Предложите метод аугментации данных и продемонстрируйте его эффективность. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghUVREQjqj4H",
        "colab_type": "text"
      },
      "source": [
        "## Часть 3. DrQA-подобная архитектура\n",
        "\n",
        "Основана на статье: Reading Wikipedia to Answer Open-Domain Questions\n",
        "\n",
        "Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes\n",
        "\n",
        "https://arxiv.org/abs/1704.00051\n",
        "\n",
        "Архитектура DrQA предложена для задачи SQuAD, но легко может быть адаптирована к текущему заданию. Модель состоит из следующих блоков:\n",
        "1. Кодировщик абзаца [paragraph encoding] – LSTM, получаящая на вход вектора слов, состоящие из: \n",
        "* эмбеддинга слова (w2v или fasttext)\n",
        "* дополнительных признаков-индикаторов, кодирующих в виде one-hot векторов часть речи слова, является ли оно именованной сущностью или нет, встречается ли слово в вопросе или нет \n",
        "* выровненного эмбеддинга вопроса, получаемого с использованием soft attention между эмбеддингами слов из абзаца и эмбеддингом вопроса.\n",
        "\n",
        "$f_{align}(p_i) = \\sum_j􏰂 a_{i,j} E(q_j)$, где $E(q_j)$ – эмбеддинг слова из вопроса. Формула для $a_{i,j}$ приведена в статье. \n",
        "\n",
        "2. Кодировщик вопроса [question encoding] – LSTM, получаящая на вход эмбеддинги слов из вопроса. Выход кодировщика: $q = 􏰂\\sum_j􏰂  b_j q_j$. Формула для $b_{j}$ приведена в статье. \n",
        "\n",
        "3. Слой предсказания. \n",
        "\n",
        "Предложите, как можно было модифицировать последний слой предсказания в архитектуре DrQA, с учетом того, что итоговое предсказание – это метка yes / no, предсказание которой проще, чем предсказание спана ответа для SQuAD.\n",
        "\n",
        "Оцените качество этой модели для решения задачи. \n",
        "\n",
        "[bonus] Замените входные эмбеддинги и все дополнительные признаки, используемые кодировщиками, на BERT эмбеддинги. Улучшит ли это качество результатов?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXmluyTFqj4P",
        "colab_type": "text"
      },
      "source": [
        "## Часть 4. BiDAF-подобная архитектура\n",
        "\n",
        "Основана на статье: Bidirectional Attention Flow for Machine Comprehension\n",
        "\n",
        "Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi\n",
        "\n",
        "https://arxiv.org/abs/1611.01603\n",
        "\n",
        "Архитектура BiDAF предложена для задачи SQuAD, но легко может быть адаптирована к текущему заданию. Модель состоит из следующих блоков:\n",
        "1. Кодировщик  получает на вход два представления слова: эмбеддинг слова и полученное из CNN посимвольное представление слова. Кодировщики для вопроса и для параграфа одинаковы. \n",
        "2. Слой внимания (детальное описание приведено в статье, см. пункт Attention Flow Layer)\n",
        "3. Промежуточный слой, который получает на вход контекстуализированные эмбеддинги слов из параграфа, состоящие из трех частей (выход кодировщика параграфа,   Query2Context (один вектор) и Context2Query (матрица) выравнивания\n",
        "\n",
        "4. Слой предсказания. \n",
        "\n",
        "Предложите, как можно было модифицировать последний слой предсказания в архитектуре BiDAF, с учетом того, что итоговое предсказание – это метка yes / no, предсказание которой проще, чем предсказание спана ответа для SQuAD.\n",
        "\n",
        "Оцените качество этой модели для решения задачи. \n",
        "\n",
        "[bonus] Замените входные эмбеддинги и все дополнительные признаки, используемые кодировщиками, на BERT эмбеддинги. Улучшит ли это качество результатов?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrPAxeHIqj4S",
        "colab_type": "text"
      },
      "source": [
        "Сравнение DrQA и BiDAF:\n",
        "    \n",
        "![](https://www.researchgate.net/profile/Felix_Wu6/publication/321069852/figure/fig1/AS:560800147881984@1510716582560/Schematic-layouts-of-the-BiDAF-left-and-DrQA-right-architectures-We-propose-to.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMXmEGfgqj4W",
        "colab_type": "text"
      },
      "source": [
        "## Часть 5. Итоги\n",
        "Напишите краткое резюме проделанной работы. Сравните результаты всех разработанных моделей. Что помогло вам в выполнении работы, чего не хватало?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogc7oO0tvPFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp gs://boolq/train.jsonl .\n",
        "!gsutil cp gs://boolq/dev.jsonl ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty11kkadvX17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyBQOB4nvcqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRqp7UyUvfh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd fastText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zo8TP1ovhuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5x22zljvjXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd .. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "642bxoWdvlI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -U catalyst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41rgZC0yvnGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nlpaug python-dotenv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIcIWvqkvpOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if Your machine doesn't support FP16, comment these 4 lines below\n",
        "!git clone https://github.com/NVIDIA/apex \n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex \n",
        "!rm -rf ./apex\n",
        "FP16_PARAMS = dict(opt_level=\"O1\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLyaqiF5vu7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "\n",
        "# Numpy & Pandas \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Matplotlib & Seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "sns.set()\n",
        "\n",
        "# Sklearn \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "# PyTorch \n",
        "import torch\n",
        "from torch import nn \n",
        "from torch.nn import functional as F \n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# FastText\n",
        "import fasttext\n",
        "\n",
        "# Transformers \n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "# Catalyst\n",
        "from catalyst.dl import SupervisedRunner\n",
        "from catalyst.dl.callbacks import AccuracyCallback, OptimizerCallback, F1ScoreCallback\n",
        "from catalyst.dl.callbacks import CheckpointCallback, InferCallback\n",
        "from catalyst.utils import set_global_seed, prepare_cudnn\n",
        "from catalyst.dl import utils\n",
        "from catalyst.dl import Callback, CallbackOrder, Runner\n",
        "from catalyst.data import BalanceClassSampler\n",
        "\n",
        "\n",
        "# NLPaug \n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as naf\n",
        "\n",
        "from nlpaug.util import Action\n",
        "from nlpaug.util.file.download import DownloadUtil\n",
        "\n",
        "# Glove for word-augmentations\n",
        "DownloadUtil.download_glove(model_name='glove.6B', dest_dir='.') # Download word2vec models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1aCQg4pvyjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5ff9782e-c233-4b0b-8ca5-81e24a69a609"
      },
      "source": [
        "# Loading data\n",
        "df_train = pd.read_json(\"/content/train.jsonl\", lines=True, orient='records')\n",
        "df_dev = pd.read_json(\"/content/dev.jsonl\", lines=True, orient=\"records\")\n",
        "\n",
        "print(f'Train df size: {df_train.shape}')\n",
        "print(f'Dev df size: {df_dev.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train df size: (9427, 4)\n",
            "Dev df size: (3270, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDl_W88M2uXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "73da8aac0a244960aa1ea306c446038f",
            "8a4fd589d122400092cd8e0ac81703f2",
            "345a75cfa92644a0b38a3627f5b42108",
            "8c226e751efe488c8bf33fc2cadca310",
            "0506668d7f5b462089a08b5dce34471b",
            "04a28ee25a21440bb2b6cdca945cedd3",
            "1fd2dd2e4de34033856e60b113a7fae7",
            "127d6fb07ed04c3fa56f86f067513cac",
            "a1108e5acfa04e54a2c3d52927ac76b7",
            "82919e548ebf4b4da8d632fc01d3fbb9",
            "d5a2c4f8a8944a00b644a7ca3a1e97c9",
            "b07464f10afb49609010944787c8c62f",
            "2b1ac659e8c541b7aac578c7ec52a38f",
            "00c52848cdf047e3aaec5881ad60ff3b",
            "4a1f304ce65a41ffaeda33448903ef5e",
            "571f317bf4e24689806e55980323bdb5",
            "b11756ce1d314566b01eb8084dc1094c",
            "82c8757c63c04ccea414fac6a554088c",
            "21843431c77c4a13ab7b000b1b42d7f1",
            "ee97699962614b9f825392c6adb828bc",
            "25ae1edde9e74903a5b23ad813455b7a",
            "d94a1000e31c4ce089163ae3f216c15b",
            "265b8d4ee5264195873d73d4b5f9df42",
            "1944539aa0d14b3eb172d317e667725e"
          ]
        },
        "outputId": "12807591-7f69-4911-d448-b31796d3c961"
      },
      "source": [
        "model_type = 'glove'\n",
        "model_path = 'glove.6B.50d.txt'\n",
        "\n",
        "\n",
        "qaug = naf.Sometimes([\n",
        "    nac.RandomCharAug(action=\"delete\", aug_char_max=7),\n",
        "    nac.RandomCharAug(action=\"insert\", aug_char_max=7),\n",
        "    naw.RandomWordAug(aug_max=5),\n",
        "    naw.WordEmbsAug(model_type=model_type, model_path=model_path, action=\"substitute\", aug_max=5),\n",
        "    nac.OcrAug(aug_word_max=5),\n",
        "    # naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\", aug_max=5)\n",
        "])\n",
        "\n",
        "paug = naf.Sometimes([\n",
        "    nac.RandomCharAug(action=\"delete\", aug_char_max=2),\n",
        "    naw.RandomWordAug(aug_max=2),\n",
        "    naw.WordEmbsAug(model_type=model_type, model_path=model_path, action=\"substitute\", aug_max=2),\n",
        "    nac.OcrAug(aug_word_max=2),\n",
        "])\n",
        "\n",
        "\n",
        "onehotter = OneHotEncoder(handle_unknown='ignore').fit(df_train.answer.values.astype(int).reshape(-1, 1))\n",
        "\n",
        "\n",
        "# Pretrained tokenizer \n",
        "pretrained_model_name = 'roberta-base'\n",
        "# pretrained_model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name) \n",
        "\n",
        "max_length = 256"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73da8aac0a244960aa1ea306c446038f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1108e5acfa04e54a2c3d52927ac76b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b11756ce1d314566b01eb8084dc1094c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRG2S6IHghlN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "154eb384-2dbf-4cdd-a893-ab7e14d0d982"
      },
      "source": [
        "p_aug = naf.Sequential([\n",
        "                       naw.WordEmbsAug(model_type='glove', model_path='glove.6B.100d.txt', action=\"insert\", aug_p=0.8), \n",
        "                       nac.RandomCharAug(action=\"delete\", aug_char_p=0.5)\n",
        "])\n",
        "\n",
        "\n",
        "p_aug.augment(df_train.iloc[0].passage)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cays Persian ( / ˈpɜːrʒən , - ʃən / ) , also known suraj by its endonym Farsi ( فارسی ārs ( fɒːɾˈsiː ) ( listen ) ) , fishhook is one of the Western upgrader Iranian languages within the Indo - Iranian branch of the Indo - European language family . It is primarily spoken in Iran , Afghanistan ( officially known as Dari since 1958 ) , and Tajikistan ( officially knw as Tajiki since the Soviet self - deception era ) , and rieit some other regions which historically dhirubhai were Persianate sieti and considered part of Greater Iran . It is written 5 , 048 . 62 in vratislav the Persian alphabet , a modified variant of the Arabic script , tonghua which itself evolved from the Aramaic pabt .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzVrXdKrJhKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cd1fe438-f7b1-443d-f78a-351b554bfa5d"
      },
      "source": [
        "def add_wrong_passage(x: pd.DataFrame, wrong_ratio=0.1):\n",
        "    inds = np.random.choice(2, len(x), p=[1 - wrong_ratio, wrong_ratio]).astype(bool)\n",
        "    oq = x.loc[inds]\n",
        "    wp = x.loc[~inds]\n",
        "\n",
        "    oq = oq.apply(lambda x: [x.question, 0, wp.sample().passage.item()], axis=1, result_type='expand')\n",
        "    oq = oq.rename(columns=dict(zip(range(3), ['question', 'answer', 'passage'])))\n",
        "    return oq \n",
        "\n",
        "def add_aug_passage(x: pd.DataFrame, ratio=0.1, aug=p_aug):\n",
        "    samples = x.sample(frac=ratio)\n",
        "    samples.passage = samples.passage.apply(p_aug.augment)\n",
        "    return samples \n",
        "\n",
        "def aug_data(x, n_transforms=2):\n",
        "    # Upsample with more wrong examples, passages are not original  \n",
        "    samples1 = [add_wrong_passage(x) for i in range(n_transforms)]\n",
        "    samples2 = [add_aug_passage(x) for i in range(n_transforms)]\n",
        "\n",
        "    x = pd.concat([*samples1, *samples2, x])\n",
        "\n",
        "    return x\n",
        "\n",
        "def pair_encode(x):  \n",
        "    encoded_pair = tokenizer.batch_encode_plus(zip(x.question, x.passage), max_length=max_length, pad_to_max_length=True, truncation_strategy=\"longest_first\")\n",
        "    return np.array(encoded_pair[\"input_ids\"]), np.array(encoded_pair[\"attention_mask\"]), x.answer.values\n",
        "\n",
        "\n",
        "def encode_data(data: pd.DataFrame, mode='train'):\n",
        "    data = data.astype({'answer': int})\n",
        "    data = data.drop('title', axis=1)\n",
        "    \n",
        "    if mode == 'train': \n",
        "        data = aug_data(data)\n",
        "\n",
        "    data = pair_encode(data)\n",
        "    return [torch.tensor(x, dtype=torch.long) for x in data]\n",
        "\n",
        "\n",
        "%time train_features_tensors = encode_data(df_train, mode='dev')\n",
        "%time dev_features_tensors = encode_data(df_dev, mode='dev')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.09 s, sys: 111 ms, total: 7.2 s\n",
            "Wall time: 7.57 s\n",
            "CPU times: user 2.34 s, sys: 22.8 ms, total: 2.37 s\n",
            "Wall time: 2.37 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_A3vdtdS8t1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "482dd87d-6b47-44b7-cddf-88617a5163af"
      },
      "source": [
        "class BQDataset(Dataset): \n",
        "    def __init__(self, data):\n",
        "        super().__init__()\n",
        "\n",
        "        # self.ids, self.attn_masks, self.tgt, self.onehot = data\n",
        "        self.ids, self.attn_masks, self.tgt = data\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, ind): \n",
        "        return {'features': self.ids[ind], \n",
        "                'attention_mask': self.attn_masks[ind], \n",
        "                'targets': self.tgt[ind],\n",
        "                # 'onehot': self.onehot[ind]\n",
        "                }\n",
        "\n",
        "batch_size = 24\n",
        "\n",
        "train_dataset = BQDataset(train_features_tensors)\n",
        "dev_dataset = BQDataset(dev_features_tensors)\n",
        "\n",
        "train_sampler = BalanceClassSampler(train_features_tensors[2], mode=\"upsampling\")\n",
        "dev_sampler = SequentialSampler(dev_dataset)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "dev_dataloader = DataLoader(dev_dataset, sampler=dev_sampler, batch_size=batch_size)\n",
        "\n",
        "len(train_dataloader), len(dev_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 137)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_a67FQylbM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5fe4bf9-bd01-4c3d-da0c-98458346b4fa"
      },
      "source": [
        "class Model(nn.Module): \n",
        "    def __init__(self, pretrained_model_name: str):\n",
        "        super().__init__() \n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name)\n",
        "\n",
        "    def n_trainable(self): \n",
        "        return sum([params.numel() for name, params in self.model.named_parameters() if params.requires_grad])\n",
        "\n",
        "    def forward(self, features, attention_mask, targets):\n",
        "        output = self.model(input_ids=features, \n",
        "                            attention_mask=attention_mask,\n",
        "                            labels=targets)\n",
        "        logits = output[1]\n",
        "        return logits \n",
        "\n",
        "\n",
        "model = Model(pretrained_model_name)\n",
        "model.to(device)\n",
        "print(f'Trainable parameters: {model.n_trainable()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable parameters: 125237762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrESKFgPs7sG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class F1ScoreCallback(Callback):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_key: str = 'targets',\n",
        "        output_key: str = 'logits',\n",
        "        activation: str = 'Sigmoid', \n",
        "        prefix: str = \"f1_score\",\n",
        "    ):\n",
        "        self.input_key = input_key\n",
        "        self.output_key = output_key\n",
        "        self.prefix = prefix\n",
        "\n",
        "        super().__init__(CallbackOrder.Metric)\n",
        "\n",
        "    def on_batch_end(self, state):\n",
        "        y_true = state.input[self.input_key].detach().cpu().numpy()\n",
        "        y_preds = state.output[self.output_key].detach().cpu().numpy().argmax(1)\n",
        "\n",
        "        score = f1_score(y_true, y_preds)\n",
        "        \n",
        "        state.batch_metrics.update({self.prefix: score})\n",
        "\n",
        "\n",
        "loaders = {\n",
        "    'train': train_dataloader, \n",
        "    'valid': dev_dataloader,\n",
        "    # 'test': test_dataloader,     \n",
        "} \n",
        "\n",
        "\n",
        "set_global_seed(33)                       # reproducibility\n",
        "prepare_cudnn(deterministic=True)           # reproducibility\n",
        "\n",
        "LOG_DIR = './logs' \n",
        "epochs = 8\n",
        "lr = 5e-5                     \n",
        "acum_step = 4\n",
        "num_cls = 2 \n",
        " \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
        "\n",
        "runner = SupervisedRunner(\n",
        "    input_key=(\n",
        "        'features',\n",
        "        'attention_mask', \n",
        "        'targets', \n",
        "    ),\n",
        "    device=device, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AtOvtxfqWsc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0700a80-e08d-4e53-ff55-4011f0ae93bd"
      },
      "source": [
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    loaders=loaders,\n",
        "    callbacks=[\n",
        "        AccuracyCallback(num_classes=num_cls),\n",
        "        F1ScoreCallback(),\n",
        "        OptimizerCallback(\n",
        "            accumulation_steps=acum_step, \n",
        "            grad_clip_params={'func': 'clip_grad_value_', 'clip_value': 1}\n",
        "            )\n",
        "    ],\n",
        "    main_metric=\"accuracy01\",\n",
        "    minimize_metric=False,\n",
        "    # fp16=FP16_PARAMS,\n",
        "    logdir=LOG_DIR,\n",
        "    num_epochs=epochs,\n",
        "    verbose=True, \n",
        "    load_best_on_end=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O0:  Pure FP32 training.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O0\n",
            "cast_model_type        : torch.float32\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : False\n",
            "loss_scale             : 1.0\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O0\n",
            "cast_model_type        : torch.float32\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : False\n",
            "loss_scale             : 1.0\n",
            "1/8 * Epoch (train): 100% 585/585 [17:16<00:00,  1.77s/it, accuracy01=0.773, f1_score=0.828, loss=0.541]\n",
            "1/8 * Epoch (valid): 100% 137/137 [01:28<00:00,  1.54it/s, accuracy01=0.833, f1_score=0.889, loss=0.435]\n",
            "[2020-06-16 15:16:34,606] \n",
            "1/8 * Epoch 1 (_base): lr=5.000e-05 | momentum=0.9000\n",
            "1/8 * Epoch 1 (train): accuracy01=0.6772 | f1_score=0.6832 | loss=0.5749\n",
            "1/8 * Epoch 1 (valid): accuracy01=0.7235 | f1_score=0.8048 | loss=0.5532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning:\n",
            "\n",
            "To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2/8 * Epoch (train): 100% 585/585 [17:17<00:00,  1.77s/it, accuracy01=0.909, f1_score=0.909, loss=0.237]\n",
            "2/8 * Epoch (valid): 100% 137/137 [01:28<00:00,  1.54it/s, accuracy01=0.833, f1_score=0.889, loss=0.569]\n",
            "[2020-06-16 15:37:21,929] \n",
            "2/8 * Epoch 2 (_base): lr=4.050e-05 | momentum=0.9000\n",
            "2/8 * Epoch 2 (train): accuracy01=0.8208 | f1_score=0.8206 | loss=0.3999\n",
            "2/8 * Epoch 2 (valid): accuracy01=0.7719 | f1_score=0.8168 | loss=0.5300\n",
            "3/8 * Epoch (train): 100% 585/585 [17:16<00:00,  1.77s/it, accuracy01=0.955, f1_score=0.960, loss=0.062]\n",
            "3/8 * Epoch (valid): 100% 137/137 [01:28<00:00,  1.54it/s, accuracy01=0.667, f1_score=0.750, loss=0.831]\n",
            "[2020-06-16 15:58:07,264] \n",
            "3/8 * Epoch 3 (_base): lr=4.500e-05 | momentum=0.9000\n",
            "3/8 * Epoch 3 (train): accuracy01=0.8967 | f1_score=0.8934 | loss=0.2579\n",
            "3/8 * Epoch 3 (valid): accuracy01=0.7844 | f1_score=0.8317 | loss=0.6072\n",
            "4/8 * Epoch (train): 100% 585/585 [17:15<00:00,  1.77s/it, accuracy01=0.955, f1_score=0.960, loss=0.183]\n",
            "4/8 * Epoch (valid): 100% 137/137 [01:28<00:00,  1.54it/s, accuracy01=0.667, f1_score=0.750, loss=0.964]\n",
            "[2020-06-16 16:18:52,630] \n",
            "4/8 * Epoch 4 (_base): lr=3.645e-05 | momentum=0.9000\n",
            "4/8 * Epoch 4 (train): accuracy01=0.9419 | f1_score=0.9401 | loss=0.1614\n",
            "4/8 * Epoch 4 (valid): accuracy01=0.7798 | f1_score=0.8257 | loss=0.6941\n",
            "5/8 * Epoch (train): 100% 585/585 [17:16<00:00,  1.77s/it, accuracy01=0.955, f1_score=0.963, loss=0.086]\n",
            "5/8 * Epoch (valid): 100% 137/137 [01:28<00:00,  1.54it/s, accuracy01=0.833, f1_score=0.889, loss=0.444]\n",
            "[2020-06-16 16:38:50,800] \n",
            "5/8 * Epoch 5 (_base): lr=4.050e-05 | momentum=0.9000\n",
            "5/8 * Epoch 5 (train): accuracy01=0.9595 | f1_score=0.9579 | loss=0.1177\n",
            "5/8 * Epoch 5 (valid): accuracy01=0.7939 | f1_score=0.8380 | loss=0.6792\n",
            "6/8 * Epoch (train): 100% 585/585 [17:17<00:00,  1.77s/it, accuracy01=1.000, f1_score=1.000, loss=0.025]\n",
            "6/8 * Epoch (valid): 100% 137/137 [01:28<00:00,  1.54it/s, accuracy01=0.833, f1_score=0.889, loss=1.141]\n",
            "[2020-06-16 16:59:36,295] \n",
            "6/8 * Epoch 6 (_base): lr=3.281e-05 | momentum=0.9000\n",
            "6/8 * Epoch 6 (train): accuracy01=0.9719 | f1_score=0.9710 | loss=0.0844\n",
            "6/8 * Epoch 6 (valid): accuracy01=0.7847 | f1_score=0.8201 | loss=0.7845\n",
            "7/8 * Epoch (train): 100% 585/585 [17:23<00:00,  1.78s/it, accuracy01=1.000, f1_score=1.000, loss=0.015]\n",
            "7/8 * Epoch (valid): 100% 137/137 [01:29<00:00,  1.53it/s, accuracy01=0.833, f1_score=0.889, loss=0.972]\n",
            "[2020-06-16 17:19:40,616] \n",
            "7/8 * Epoch 7 (_base): lr=3.645e-05 | momentum=0.9000\n",
            "7/8 * Epoch 7 (train): accuracy01=0.9798 | f1_score=0.9790 | loss=0.0634\n",
            "7/8 * Epoch 7 (valid): accuracy01=0.7875 | f1_score=0.8240 | loss=0.9126\n",
            "8/8 * Epoch (train): 100% 585/585 [17:27<00:00,  1.79s/it, accuracy01=1.000, f1_score=1.000, loss=0.018]\n",
            "8/8 * Epoch (valid): 100% 137/137 [01:29<00:00,  1.53it/s, accuracy01=0.833, f1_score=0.889, loss=0.999]\n",
            "[2020-06-16 17:39:47,566] \n",
            "8/8 * Epoch 8 (_base): lr=2.952e-05 | momentum=0.9000\n",
            "8/8 * Epoch 8 (train): accuracy01=0.9835 | f1_score=0.9826 | loss=0.0514\n",
            "8/8 * Epoch 8 (valid): accuracy01=0.7972 | f1_score=0.8349 | loss=0.7366\n",
            "Top best models:\n",
            "logs/checkpoints/train.8.pth\t0.7972\n",
            "=> Loading checkpoint logs/checkpoints/best_full.pth\n",
            "loaded state checkpoint logs/checkpoints/best_full.pth (global epoch 8, epoch 8, stage train)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLAMnQiiN9Wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "5e420e32-c5d8-4a5c-a1e2-906a785d3750"
      },
      "source": [
        "def calc_accuracy(y_preds, y_true):\n",
        "    acc = accuracy_score(y_true, y_preds)\n",
        "    print(f'Accuracy: {acc:.3f}')\n",
        "\n",
        "\n",
        "def calc_accuracy_per_cls(y_preds, y_true):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_preds).ravel()\n",
        "    acc1, acc2 = tn / (tn + fn), tp / (tp + fp)\n",
        "    print(f'Accuracy class 1: {acc1:.3f}, class 2: {acc2:.3f}')\n",
        "\n",
        "\n",
        "def calc_f1_score(y_preds, y_true): \n",
        "    f1 = f1_score(y_true, y_preds)\n",
        "    print(f'F1 score: {f1:.3f}') \n",
        "\n",
        "\n",
        "runner.infer(\n",
        "    model=model,\n",
        "    loaders={'test': dev_dataloader},\n",
        "    callbacks=[\n",
        "        CheckpointCallback(\n",
        "            resume=f\"{LOG_DIR}/checkpoints/best.pth\"\n",
        "        ),\n",
        "        InferCallback(),\n",
        "    ],   \n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "y_preds = runner.callbacks[0].predictions['logits'].argmax(1)\n",
        "y_true = dev_features_tensors[2].cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O0:  Pure FP32 training.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O0\n",
            "cast_model_type        : torch.float32\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : False\n",
            "loss_scale             : 1.0\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O0\n",
            "cast_model_type        : torch.float32\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : False\n",
            "loss_scale             : 1.0\n",
            "=> Loading checkpoint ./logs/checkpoints/best.pth\n",
            "loaded state checkpoint ./logs/checkpoints/best.pth (global epoch 7, epoch 7, stage train)\n",
            "1/1 * Epoch (test): 100% 137/137 [02:39<00:00,  1.16s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9BHbtsNPwvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "45f5feeb-f3db-435e-91f0-dcef8de48737"
      },
      "source": [
        "calc_accuracy(y_preds, y_true)\n",
        "calc_accuracy_per_cls(y_preds, y_true)\n",
        "calc_f1_score(y_preds, y_true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.797\n",
            "Accuracy class 1: 0.739, class 2: 0.831\n",
            "F1 score: 0.838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp5yCF38QY_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f135762-1165-4fbd-b728-c003ec978b47"
      },
      "source": [
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    loaders=loaders,\n",
        "    callbacks=[\n",
        "        AccuracyCallback(num_classes=num_cls),\n",
        "        F1ScoreCallback(),\n",
        "        OptimizerCallback(\n",
        "            accumulation_steps=acum_step, \n",
        "            grad_clip_params={'func': 'clip_grad_value_', 'clip_value': 1}\n",
        "            )\n",
        "    ],\n",
        "    main_metric=\"accuracy01\",\n",
        "    minimize_metric=False,\n",
        "    fp16=FP16_PARAMS,\n",
        "    logdir=LOG_DIR,\n",
        "    num_epochs=epochs,\n",
        "    verbose=True, \n",
        "    load_best_on_end=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "1/8 * Epoch (train):  64% 315/490 [18:05<09:59,  3.43s/it, accuracy01=0.542, f1_score=0.667, loss=0.758]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "1/8 * Epoch (train):  85% 415/490 [23:50<04:17,  3.44s/it, accuracy01=0.750, f1_score=0.700, loss=0.422]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "1/8 * Epoch (train): 100% 490/490 [28:07<00:00,  3.44s/it, accuracy01=0.833, f1_score=0.857, loss=0.464]\n",
            "1/8 * Epoch (valid): 100% 137/137 [02:39<00:00,  1.17s/it, accuracy01=0.833, f1_score=0.889, loss=0.567]\n",
            "[2020-06-16 18:22:50,990] \n",
            "1/8 * Epoch 1 (_base): lr=5.000e-05 | momentum=0.9000\n",
            "1/8 * Epoch 1 (train): accuracy01=0.6161 | f1_score=0.5835 | loss=0.6436\n",
            "1/8 * Epoch 1 (valid): accuracy01=0.7199 | f1_score=0.7620 | loss=0.5446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning:\n",
            "\n",
            "Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning:\n",
            "\n",
            "To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2/8 * Epoch (train): 100% 490/490 [28:13<00:00,  3.46s/it, accuracy01=0.750, f1_score=0.769, loss=0.809]\n",
            "2/8 * Epoch (valid): 100% 137/137 [02:38<00:00,  1.15s/it, accuracy01=1.000, f1_score=1.000, loss=0.197]\n",
            "[2020-06-16 18:55:44,356] \n",
            "2/8 * Epoch 2 (_base): lr=4.050e-05 | momentum=0.9000\n",
            "2/8 * Epoch 2 (train): accuracy01=0.7903 | f1_score=0.7816 | loss=0.4598\n",
            "2/8 * Epoch 2 (valid): accuracy01=0.7713 | f1_score=0.8180 | loss=0.5150\n",
            "3/8 * Epoch (train):  15% 75/490 [04:19<23:49,  3.45s/it, accuracy01=0.833, f1_score=0.875, loss=0.394]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "3/8 * Epoch (train): 100% 490/490 [28:15<00:00,  3.46s/it, accuracy01=0.667, f1_score=0.667, loss=0.637]\n",
            "3/8 * Epoch (valid): 100% 137/137 [02:39<00:00,  1.17s/it, accuracy01=0.833, f1_score=0.889, loss=0.467]\n",
            "[2020-06-16 19:28:41,123] \n",
            "3/8 * Epoch 3 (_base): lr=4.500e-05 | momentum=0.9000\n",
            "3/8 * Epoch 3 (train): accuracy01=0.8827 | f1_score=0.8787 | loss=0.2968\n",
            "3/8 * Epoch 3 (valid): accuracy01=0.7807 | f1_score=0.8279 | loss=0.5498\n",
            "4/8 * Epoch (train): 100% 490/490 [28:08<00:00,  3.45s/it, accuracy01=0.917, f1_score=0.889, loss=0.397]\n",
            "4/8 * Epoch (valid): 100% 137/137 [02:39<00:00,  1.16s/it, accuracy01=0.833, f1_score=0.889, loss=0.862]\n",
            "[2020-06-16 20:01:29,654] \n",
            "4/8 * Epoch 4 (_base): lr=3.645e-05 | momentum=0.9000\n",
            "4/8 * Epoch 4 (train): accuracy01=0.9311 | f1_score=0.9282 | loss=0.1859\n",
            "4/8 * Epoch 4 (valid): accuracy01=0.7817 | f1_score=0.8164 | loss=0.6500\n",
            "5/8 * Epoch (train): 100% 490/490 [28:07<00:00,  3.44s/it, accuracy01=0.917, f1_score=0.909, loss=0.292]\n",
            "5/8 * Epoch (valid): 100% 137/137 [02:39<00:00,  1.17s/it, accuracy01=0.833, f1_score=0.889, loss=0.645]\n",
            "[2020-06-16 20:34:15,467] \n",
            "5/8 * Epoch 5 (_base): lr=4.050e-05 | momentum=0.9000\n",
            "5/8 * Epoch 5 (train): accuracy01=0.9648 | f1_score=0.9637 | loss=0.1094\n",
            "5/8 * Epoch 5 (valid): accuracy01=0.7884 | f1_score=0.8312 | loss=0.7145\n",
            "6/8 * Epoch (train):  57% 277/490 [15:54<12:11,  3.44s/it, accuracy01=1.000, f1_score=1.000, loss=0.047]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "6/8 * Epoch (train): 100% 490/490 [28:07<00:00,  3.44s/it, accuracy01=1.000, f1_score=1.000, loss=0.009]\n",
            "6/8 * Epoch (valid): 100% 137/137 [02:39<00:00,  1.17s/it, accuracy01=0.833, f1_score=0.889, loss=0.768]\n",
            "[2020-06-16 21:07:05,766] \n",
            "6/8 * Epoch 6 (_base): lr=3.281e-05 | momentum=0.9000\n",
            "6/8 * Epoch 6 (train): accuracy01=0.9719 | f1_score=0.9715 | loss=0.0845\n",
            "6/8 * Epoch 6 (valid): accuracy01=0.7951 | f1_score=0.8366 | loss=0.8900\n",
            "7/8 * Epoch (train): 100% 490/490 [28:04<00:00,  3.44s/it, accuracy01=1.000, f1_score=1.000, loss=0.012]\n",
            "7/8 * Epoch (valid): 100% 137/137 [02:38<00:00,  1.15s/it, accuracy01=0.833, f1_score=0.889, loss=1.063]\n",
            "[2020-06-16 21:39:51,162] \n",
            "7/8 * Epoch 7 (_base): lr=3.645e-05 | momentum=0.9000\n",
            "7/8 * Epoch 7 (train): accuracy01=0.9816 | f1_score=0.9805 | loss=0.0580\n",
            "7/8 * Epoch 7 (valid): accuracy01=0.8015 | f1_score=0.8402 | loss=0.9237\n",
            "8/8 * Epoch (train): 100% 490/490 [28:05<00:00,  3.44s/it, accuracy01=1.000, f1_score=1.000, loss=0.001]\n",
            "8/8 * Epoch (valid): 100% 137/137 [02:39<00:00,  1.17s/it, accuracy01=0.833, f1_score=0.889, loss=1.068]\n",
            "[2020-06-16 22:12:38,048] \n",
            "8/8 * Epoch 8 (_base): lr=2.952e-05 | momentum=0.9000\n",
            "8/8 * Epoch 8 (train): accuracy01=0.9847 | f1_score=0.9838 | loss=0.0482\n",
            "8/8 * Epoch 8 (valid): accuracy01=0.7878 | f1_score=0.8234 | loss=0.9488\n",
            "Top best models:\n",
            "logs/checkpoints/train.7.pth\t0.8015\n",
            "=> Loading checkpoint logs/checkpoints/best_full.pth\n",
            "loaded state checkpoint logs/checkpoints/best_full.pth (global epoch 7, epoch 7, stage train)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q934uaVIQn4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "39f6ed82-f85a-4c35-cdba-20ffb71557b4"
      },
      "source": [
        "calc_accuracy(y_preds, y_true)\n",
        "calc_accuracy_per_cls(y_preds, y_true)\n",
        "calc_f1_score(y_preds, y_true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.787\n",
            "Accuracy class 1: 0.711, class 2: 0.837\n",
            "F1 score: 0.827\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}